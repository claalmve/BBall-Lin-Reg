{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4- Intro to Modeling + Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back to Week 4 of `Balling with Data`! Today, we'll finally begin **modeling**, the most exciting part of this project! For today's notebook, we won't be going too in-depth into what we'll be doing, rather we'll be showing you some demos and you're going to begin applying those concepts to your own data. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "# If any of these don't work, try doing `pip install _____`, or try looking up the error message.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os.path\n",
    "from os import path\n",
    "import math\n",
    "import datetime\n",
    "import unidecode\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So... what is modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've reached the most exciting part of the project-- modeling! Now, what this part of the project entails is us being able to **predict different stats based off of the features we've extracted and cleaned!**\n",
    "\n",
    "However, in order for us to completely, understand how this works, we'll need to make sure we've got a good sense of **machine learning**, and how we can use different **machine learning models** to help us identify different underlying trends in the data that we might not be able to typically see! Let's get into a video that introduces most of what we'll be covering today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Intro: Machine Learning Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/ukzFI9rgwfU\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10e0e3710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('ukzFI9rgwfU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a great article briefly explanining a bunch of the different models we'll be using for the project over the next few weeks!\n",
    "\n",
    "[**All ML models explained in 6 mins**](https://towardsdatascience.com/all-machine-learning-models-explained-in-6-minutes-9fe30ff6776a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's get into Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first fundamental part into Machine Learning, we'll first learn about **Linear Regression**. As I'm sure many of you have learned about this in the past, linear regression can take on a variety of different forms.\n",
    "\n",
    "You might know it as something of the following:\n",
    "\n",
    "$$y = ax + b$$\n",
    "\n",
    "where we have the independent variable `x` multiplied and added by different constants that we've found that minimize the **least-squares error** between the line and the different points. In the scope of this project **`x` would be our different values for features, and `y` would be our prediction for those given values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what we can clearly see is that the equation is above is a little too simple use in our case. For our project, we're working with multidimensional data, with a variety of different inputs for features. \n",
    "\n",
    "**So, how can we translate this into a higher dimension using Linear Algebra? (Hint: you guys might've seen this in different classes before)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to translate this, let's take a look at the most common/accurate way to find the \"best-fitting line\" for all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way to find the best fit line for all the points is with **ordinary least squares**. What you might've seen in the past with something like $y = ax + b$ is that we want to calculate what the ideal slope (a) and intercept are (b) in order to find the line that minimizes the **squared error between the points**. Now that we've translated that equation to account for more variables and dimensions, let's take a look at the Linear Algebra way of viewing Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://static-assets.imageservice.cloud/2873957/choosing-the-correct-type-of-regression-analysis-statistics-by-jim.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little image of least-squares!\n",
    "from IPython.display import Image\n",
    "Image(url=\"https://static-assets.imageservice.cloud/2873957/choosing-the-correct-type-of-regression-analysis-statistics-by-jim.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving a system of linear equations:\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "Ordinary Least Squares to minimize the sum of squared residuals (or the squared error):\n",
    "\n",
    "$$\\hat{\\beta}_{OLS} = \\underset{\\beta}{\\operatorname{argmin}} \\Vert X\\beta - y\\Vert_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the exact loss function and take derivative of function to find the optimal weights (coefficients) for our model:\n",
    "\n",
    "$$ L(\\beta) = \\sum_{i=1}^{n}(x_i^T\\beta - y_i)^2 = \\Vert X\\beta - y\\Vert_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite this expression and FOIL.\n",
    "\n",
    "$$ = (X\\beta - y)^T(X\\beta - y)$$$$ = (X\\beta)^T(X\\beta) - (X\\beta)^Ty - y^TX\\beta + y^Ty $$$$ = \\beta^TX^TX\\beta - 2\\beta^TX^Ty + y^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the derivative of the equation to find the most optimal values for our weights/coefficients.\n",
    "\n",
    "$$ \\nabla_\\beta L(\\beta) = \\nabla_\\beta (\\beta^TX^TX\\beta - 2\\beta^TX^Ty + y^Ty)$$$$ = \\nabla_\\beta(\\beta^TX^TX\\beta) - 2\\nabla_\\beta(\\beta^TX^Ty) + \\nabla_\\beta(y^Ty)$$$$ = 2X^TX\\beta - 2X^Ty = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, \n",
    "$$ X^TX\\hat{\\beta}_{OLS} = X^Ty$$$$ \\hat{\\beta}_{OLS} = (X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we have proven that we can find the analytical solution to the Least Squares problem, and we can find the best weights for our model to minimize the squared error between our predictions and their actual values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note:** Take the inverse of $X^TX$ is not always computationally feasible/possible. In these cases, we might need to rely on algorithms like **gradient descent** to find the optimal values for $\\beta$.\n",
    "\n",
    "However, for all intents and purposes of this part of the project, this equation should be computable, and you should be able to easily derive the analytical solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to derive the analytical solution using our data! **Remember, `X` is our feature matrix, `y` are our actual values, and $\\hat{\\beta}$ are our different weights for our model.** Feel free to ask us any questions with this-- we know we're kind of just laying this on you guys, but we're sure that you guys will be able to pick it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POTENTIALLY USEFUL CLASS, if you end up using .apply for normalizing the dataframe. ###\n",
    "\n",
    "# Takes advantage of Pandas's apply method\n",
    "class Denormalize():\n",
    "    \"\"\"\n",
    "    Stores variables to denormalize the different normalized columns later.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.stds = {}\n",
    "        \n",
    "    def add_col(self, col):\n",
    "        self.means[col.name] = np.mean(col)\n",
    "        self.stds[col.name] = np.std(col)\n",
    "    \n",
    "    def get_means(self):\n",
    "        return self.means\n",
    "    \n",
    "    def get_stds(self):\n",
    "        return self.stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some potentially useful things to know/resources**:\n",
    "1. Matrix multiplication can be done with the '@' sign.\n",
    "2. You may want to look into `np.linalg.inv` if you're stuck.\n",
    "3. Remember, we need to make sure our features/predictions are normalized! Try to remember what is required in order for us to normalize the columns, and then un-normalize our predictions once we're done with the regression. (Hint: previous notebook might've had some info about it)\n",
    "4. Look into how Panda's `.apply` method works, and see what's printed out when you call it on a dataframe!\n",
    "5. Look above at the `Denormalize` class. It can be useful for keeping track of different means and standard deviations, so you know how to convert them back when it comes time to give raw predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've been able to make some headway into creating the model, try and see how you can make it more accurate (plot different features)! See which ones might be worser for our model (ones with more outliers), and see if there's some additional **feature selection** that could help your model become more accurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>NCAAB_assists</th>\n",
       "      <th>NCAAB_blocks</th>\n",
       "      <th>NCAAB_field_goal_attempts</th>\n",
       "      <th>NCAAB_field_goal_percentage</th>\n",
       "      <th>NCAAB_field_goals</th>\n",
       "      <th>NCAAB_free_throw_attempt_rate</th>\n",
       "      <th>NCAAB_free_throw_attempts</th>\n",
       "      <th>NCAAB_free_throw_percentage</th>\n",
       "      <th>NCAAB_free_throws</th>\n",
       "      <th>...</th>\n",
       "      <th>NCAAB_two_point_percentage</th>\n",
       "      <th>NCAAB_win_shares</th>\n",
       "      <th>NBA_assists</th>\n",
       "      <th>NBA_blocks</th>\n",
       "      <th>NBA_points</th>\n",
       "      <th>NBA_steals</th>\n",
       "      <th>NBA_total_rebounds</th>\n",
       "      <th>Center</th>\n",
       "      <th>Forward</th>\n",
       "      <th>Guard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Landry Fields</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.696</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521</td>\n",
       "      <td>6.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy Rautins</td>\n",
       "      <td>171.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patrick Patterson</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.348</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gani Lawal</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.562</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  NCAAB_assists  NCAAB_blocks  NCAAB_field_goal_attempts  \\\n",
       "0      Landry Fields           89.0          25.0                      506.0   \n",
       "1       Andy Rautins          171.0           8.0                      297.0   \n",
       "2  Patrick Patterson           36.0          51.0                      374.0   \n",
       "3         Gani Lawal           15.0          49.0                      325.0   \n",
       "4       Cole Aldrich           31.0         125.0                      265.0   \n",
       "\n",
       "   NCAAB_field_goal_percentage  NCAAB_field_goals  \\\n",
       "0                        0.490              248.0   \n",
       "1                        0.438              130.0   \n",
       "2                        0.575              215.0   \n",
       "3                        0.529              172.0   \n",
       "4                        0.562              149.0   \n",
       "\n",
       "   NCAAB_free_throw_attempt_rate  NCAAB_free_throw_attempts  \\\n",
       "0                          0.508                      257.0   \n",
       "1                          0.273                       81.0   \n",
       "2                          0.348                      130.0   \n",
       "3                          0.683                      222.0   \n",
       "4                          0.600                      159.0   \n",
       "\n",
       "   NCAAB_free_throw_percentage  NCAAB_free_throws  ...  \\\n",
       "0                        0.696              179.0  ...   \n",
       "1                        0.815               66.0  ...   \n",
       "2                        0.692               90.0  ...   \n",
       "3                        0.572              127.0  ...   \n",
       "4                        0.679              108.0  ...   \n",
       "\n",
       "   NCAAB_two_point_percentage  NCAAB_win_shares  NBA_assists  NBA_blocks  \\\n",
       "0                       0.521               6.0        155.0        17.0   \n",
       "1                       0.571               4.9          3.0         0.0   \n",
       "2                       0.626               7.0         41.0        37.0   \n",
       "3                       0.531               4.1          0.0         0.0   \n",
       "4                       0.562               5.9          4.0         7.0   \n",
       "\n",
       "   NBA_points  NBA_steals  NBA_total_rebounds  Center  Forward  Guard  \n",
       "0       797.0        80.0               521.0       0        0      1  \n",
       "1         8.0         1.0                 1.0       0        0      1  \n",
       "2       328.0        17.0               200.0       0        1      0  \n",
       "3         0.0         0.0                 0.0       0        1      0  \n",
       "4        18.0         5.0                35.0       1        0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in data here. The name of your data might be different, replace it below if this cell doesn't work!\n",
    "data = pd.read_csv(\"data/player_data_final.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SANDBOX AREA FOR FINDING THE ANALYTICAL SOLUTION TO THE DIFFERENT WEIGHTS\n",
    "\n",
    "weights = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, using the weights, predict the different stats of the training data, and denormalize it so we can see\n",
    "# the different raw predictions of rookie stat lines!\n",
    "norm_preds = ...\n",
    "raw_preds = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our different our different predictions, particularly with `Jordan Loyd`. What is something that you see that isn't right here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using Sklearn, we can do the same thing we've done up above with just a few lines of code! Start by importing `LinearRegression` and reading up on the documentation for how you can get it working!\n",
    "\n",
    "With sklearn's `LinearRegression`, we're able to add in a bunch of different parameters into our model to have it more accurately predict different stats!\n",
    "\n",
    "Take a look here at the documentation for a closer look: [Linear Regression documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "Additionally, here's a few lines to get you started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression(fit_intercept=True) # Fitting against an additional intercept column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, fit the linear model to our data, save the different weights, and have predict the different stats based\n",
    "# off of the training data!\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! Now, you've successfully been able to **implement linear regression from scratch and use sklearn's Linear Regression library for easier predictive use in the future!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for future reference, we're going to save our predictions here so that we can compare them with other models in the future!\n",
    "raw_preds.to_csv(\"lin_reg_preds.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
